{
  "name": "node-core-audio",
  "version": "0.3.9",
  "author": {
    "name": "Mike Vegeto",
    "email": "michael.vegeto@gmail.com",
    "url": "http://mikevegeto.com/"
  },
  "contributors": [
    {
      "name": "Marc J. Schmidt",
      "email": "marc@kryn.org",
      "url": "http://marcjschmidt.de/"
    },
    {
      "name": "Jeremiah Senkpiel",
      "email": "fishrock123@rocketmail.com",
      "url": "http://searchbeam.jit.su/"
    }
  ],
  "dependencies": {
    "audio-streamer": ">= 0.1.0",
    "fft": "~0.2.1",
    "node-waveheader": "git://github.com/mrose17/node-waveheader.git",
    "portfinder": "0.2.1"
  },
  "description": "Core native node.js audio functionality, including sound card access and audio streaming",
  "main": "./node-core-audio",
  "engines": {
    "node": ">=0.8.0"
  },
  "keywords": [
    "audio",
    "dsp",
    "processing",
    "portaudio",
    "sound",
    "synth",
    "signal",
    "streaming",
    "buffer"
  ],
  "licenses": [
    {
      "type": "MIT",
      "url": "http://raw.github.com/ZECTBynmo/node-core-audio/master/LICENSE"
    }
  ],
  "repository": {
    "type": "git",
    "url": "http://github.com/ZECTBynmo/node-core-audio.git"
  },
  "scripts": {
    "install": "node-gyp rebuild"
  },
  "gypfile": true,
  "readme": "Node Core Audio\r\n==================\r\n\r\n![alt tag](https://nodei.co/npm-dl/node-core-audio.png)\r\n\r\nA C++ extension for node.js that gives javascript access to audio buffers and basic audio processing functionality\r\n\r\n<a href=\"http://flattr.com/thing/1404406/\" target=\"_blank\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this\" title=\"Flattr this\" border=\"0\" /></a>\r\n\r\nRight now, it's basically a node.js binding for PortAudio.\r\n\r\nInstallation\r\n=====\r\n\r\n```\r\nnpm install node-core-audio\r\n```\r\n\r\nDisclaimer\r\n=====\r\n\r\nI am actively working on this, but if you want to see it happen faster, please send me an email!\r\n\r\nBasic Usage\r\n=====\r\n\r\nBelow is the most basic use of the audio engine. We create a new instance of\r\nnode-core-audio, and then give it our processing function. The audio engine\r\nwill call the audio callback whenever it needs an output buffer to send to\r\nthe sound card.\r\n\r\n```javascript\r\n// Create a new instance of node-core-audio\r\nvar coreAudio = require(\"node-core-audio\");\r\n\r\n// Create a new audio engine\r\nvar engine = coreAudio.createNewAudioEngine();\r\n\r\n// Add an audio processing callback\r\n// This function accepts an input buffer coming from the sound card,\r\n// and returns an ourput buffer to be sent to your speakers.\r\n//\r\n// Note: This function must return an output buffer\r\nfunction processAudio( inputBuffer ) {\r\n\tconsole.log( inputBuffer.length + \" channels\" );\r\n\tconsole.log( \"Channel 0 has \" = inputBuffer[0].length + \" samples\" );\r\n\r\n\treturn inputBuffer;\r\n}\r\n\r\nengine.addAudioCallback( processAudio );\r\n```\r\n\r\n// Alternatively, you can read/write samples to the sound card manually\r\n```javascript\r\nvar engine = coreAudio.createNewAudioEngine();\r\n\r\n// Grab a buffer\r\nvar buffer = engine.read();\r\n\r\n// Silence the 0th channel\r\nfor( var iSample=0; iSample<inputBuffer[0].length; ++iSample )\r\n\tbuffer[0][iSample] = 0.0;\r\n\r\n// Send the buffer back to the sound card\r\nengine.write( buffer );\r\n```\r\n\r\nImportant! Processing Thread\r\n=====\r\nWhen you are writing code inside of your audio callback, you are operating on\r\nthe processing thread of the application. This high priority environment means you\r\nshould try to think about performance as much as possible. Allocations and other\r\ncomplex operations are possible, but dangerous.\r\n\r\nIF YOU TAKE TOO LONG TO RETURN A BUFFER TO THE SOUND CARD, YOU WILL HAVE AUDIO DROPOUTS\r\n\r\nThe basic principle is that you should have everything ready to go before you enter\r\nthe processing function. Buffers, objects, and functions should be created in a constructor or static function outside of the audio callback whenever possible. The\r\nexamples in this readme are not necessarily good practice as far as performance is concerned.\r\n\r\nThe callback is only called if all buffers has been processed by the soundcard.\r\n\r\nAudio Engine Options\r\n=====\r\n* sampleRate [default 44100]\r\n  * Sample rate - number of samples per second in the audio stream\r\n* sampleFormat [default sampleFormatFloat32]\r\n  * Bit depth - Number of bits used to represent sample values\r\n  * formats are sampleFormatFloat32, sampleFormatInt32, sampleFormatInt24, sampleFormatInt16, sampleFormatInt8, sampleFormatUInt8.\r\n* framesPerBuffer [default 256]\r\n  * Buffer length - Number of samples per buffer\r\n* interleaved [default false]\r\n  * Interleaved / Deinterleaved - determines whether samples are given to you as a two dimensional array (buffer[channel][sample]) (deinterleaved) or one buffer with samples from alternating channels (interleaved).\r\n* inputChannels [default 2]\r\n  * Input channels - number of input channels\r\n* outputChannels [default 2]\r\n  * Output channels - number of output channels\r\n* inputDevice [default to Pa_GetDefaultInputDevice]\r\n  * Input device - id of the input device\r\n* outputDevice [default to Pa_GetDefaultOutputDevice]\r\n  * Output device - id of the output device\r\n\r\nAPI\r\n=====\r\nFirst things first\r\n```javascript\r\nvar coreAudio = require(\"node-core-audio\");\r\n```\r\nCreate and audio processing function\r\n```javascript\r\nfunction processAudio( inputBuffer ) {\r\n    // Just print the value of the first sample on the left channel\r\n    console.log( inputBuffer[0][0] );\r\n}\r\n```\r\n\r\nInitialize the audio engine and setup the processing loop\r\n```javascript\r\nvar engine = coreAudio.createNewAudioEngine();\r\n\r\nengine.addAudioCallback( processAudio );\r\n```\r\n\r\nGeneral functionality\r\n```javascript\r\n// Returns whether the audio engine is active\r\nbool engine.isActive();\r\n\r\n// Updates the parameters and restarts the engine. All keys from getOptions() are available.\r\nengine.setOptions({\r\n\tinputChannels: 2\r\n});\r\n\r\n// Returns all parameters\r\narray engine.getOptions();\r\n\r\n// Reads buffer of the input of the soundcard and returns as array.\r\n// Note: this is a blocking call, don't take too long!\r\narray engine.read();\r\n\r\n// Writes the buffer to the output of the soundcard. Returns false if underflowed.\r\n// notic: blocking i/o\r\nbool engine.write(array input);\r\n\r\n// Returns the name of a given device\r\nstring engine.getDeviceName( int inputDeviceIndex );\r\n\r\n// Returns the total number of audio devices\r\nint engine.getNumDevices();\r\n```\r\n\r\nKnown Issues / TODO\r\n=====\r\n\r\n* Add FFTW to C++ extension, so you can get fast FFT's from javascript, and also register for the FFT of incoming audio, rather than the audio itself\r\n* Add support for streaming audio over sockets\r\n\r\n\r\nLicense\r\n=====\r\nMIT - See LICENSE file.\r\n\r\nCopyright Mike Vegeto, 2013\r\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/ZECTBynmo/node-core-audio/issues"
  },
  "homepage": "https://github.com/ZECTBynmo/node-core-audio",
  "_id": "node-core-audio@0.3.9",
  "dist": {
    "shasum": "4993f93447949718c963165739aa4726b2e1cdba"
  },
  "_from": "node-core-audio@",
  "_resolved": "https://registry.npmjs.org/node-core-audio/-/node-core-audio-0.3.9.tgz"
}
